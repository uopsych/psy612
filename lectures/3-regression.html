<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Univariate regression</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Univariate regression

---





## Last time

- Correlation as inferential test
   - Power 
   
- Fisher's r to z transformation

- Correlation matrices

- Interpreting effect size

---

## Today

**Regression**

- What is it? Why is it useful

- Nuts and bolts

  - Equation

  - Ordinary least squares

  - Interpretation
  
---

## Regression

Regression is a general data analytic system, meaning lots of things fall under the umbrella of regression. This system can handle a vareity of forms of relations, although all forms have to be specified in a linear way. Usefully, we can incorporate IVs of all nature -- continuous, categorical, nominal, orderinal....

The output of regression includes both effect sizes and, if using frequentist or Bayesian software, statistial significance. We can also incorporate multiple influences (IVs) and account for their intercorrelations. 

---

### Regression

- **Scientific** use: explaining the influence of one or more variables on some outcome. 

  + Does this intervention affect reaction time?
  + Does self-esteem predict relationship quality?
  
- **Prediction** use: We can develop models based on what's happened in the past to predict what will happen in the fugure.

  + Insurance premiums
  + Graduate school... success?
  
- **Adjustment**: Statistically control for known effects

  + If everyone had the same level of SES, would abuse still be associated with criminal behavior?

---

## Regression equation

What is a regression equation?

- Functional relatioship

  - Ideally like a physical law `\((E = MC^2)\)`
  
  - In practice, it's never as robust as that
  
How do we uncover the relationship?

---

### How does Y vary with X?

- The regression of Y (DV) on X (IV) corresponds to the line that gives the mean value of Y corresponding to each possible value of X

- `\(\large E(Y|X)\)`

- "Our best guess" regardless of whether our model includes categories or continuous predictor variables

---

## Regression Equation

`$$\Large Y = b_{0} + b_{1}X +e$$`

`$$\Large \hat{Y} = b_{0} + b_{1}X$$`

???

`\(\hat{Y}\)` signifies the predicted score -- no error

The difference between the predicted and observed score is the residual ($e_i$)

There is a different e value for each observation in the dataset
---

## OLS
- How do we find the regression estimates? 
- Ordinary Least Squares (OLS) estimation
- Minimizes deviations 

$$ min\sum(Y_{i}-\hat{Y})^{2} $$ 

- Other estimation procedures possible (and necessary in some cases)

---

 


![](3-regression_files/figure-html/plot1-1.png)&lt;!-- --&gt;

---

![](3-regression_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;


---

![](3-regression_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;



---

![](3-regression_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;


---
`$$\Large Y = b_{0} + b_{1}X +e$$`

`$$\Large \hat{Y} = b_{0} + b_{1}X$$`

`$$\Large Y_i = \hat{Y_i} + e_i$$`

`$$\Large e_i = Y_i - \hat{Y_i}$$`

---

## OLS

The line that yields the smallest sum of squared deviations

`$$\Large \Sigma(Y_i - \hat{Y_i})^2$$`
`$$\Large = \Sigma(Y_i - (b_0+b_{1}X_i))^2$$`
`$$\Large = \Sigma(e_i)^2$$`

--

In order to find the OLS solution, you could try many different coefficients `\((b_0 \text{ and } b_{1})\)` until you find the one with the smallest sum squared deviation. Luckily, there are simple calculations that will yield the OLS solution every time.

---
## Regression coefficient, `\(b_{1}\)`

`$$\large b_{1} = \frac{cov_{XY}}{s_{x}^{2}} = r_{xy} \frac{s_{y}}{s_{x}}$$`

`$$\large r_{xy} = \frac{s_{xy}}{s_xs_y}$$`

- The regression coefficient (slope) equals the estimated change in Y for a 1-unit change in X  

---

`$$\large b_{1} = r_{xy} \frac{s_{y}}{s_{x}}$$`


If the variance of both X and Y is equal to 1: 

`$$\large b_1 = \frac{s_{xy}}{s_x^2}=\frac{r_{xy}}{1^2} = \beta_{yx} = b_{yx}^*$$`

---

## Standardized regression equation

`$$\large Y = b_{yx}^*X+e$$`

`$$\large b_{yx}^* = b_{yx}\frac{s_x}{s_y}$$`
--

According to this regression equation, when `\(X = 0, Y = 0\)`. Our interpretation of the coefficient is that a one-standard deviation increase in X is associated with a `\(b_{yx}^*\)` standard deviation increase in Y. Our regression coefficient is equivlant to the correlation coefficient *when we have only one predictor in our model.*

---

## Estimating the intercept, `\(b_0\)`

- intercept serves to adjust for differences in means between X and Y

`$$\Large \hat{Y} = \bar{Y} + r_{xy} \frac{s_{y}}{s_{x}}(X-\bar{X})$$`
- if standardized, intercept drops out  

- otherwise, intercept is where regression line crosses the y-axis at X = 0  

???
##Make this point
- Also, notice that when `\(X = \bar{X}\)` the regression line goes through  `\(\bar{Y}\)`

???
`$$\Large b_0 = \bar{Y} - b_1\bar{X}$$`

---

## Example




```r
galton.data &lt;- psychTools::galton
head(galton.data)
```

```
##   parent child
## 1   70.5  61.7
## 2   68.5  61.7
## 3   65.5  61.7
## 4   64.5  61.7
## 5   64.0  61.7
## 6   67.5  62.2
```

```r
describe(galton.data, fast = T)
```

```
##        vars   n  mean   sd  min  max range   se
## parent    1 928 68.31 1.79 64.0 73.0     9 0.06
## child     2 928 68.09 2.52 61.7 73.7    12 0.08
```

```r
cor(galton.data)
```

```
##           parent     child
## parent 1.0000000 0.4587624
## child  0.4587624 1.0000000
```

---

If we regress child height onto parents':


```r
r = cor(galton.data)[2,1]
m_parent = mean(galton.data$parent)
m_child = mean(galton.data$child)
s_parent = sd(galton.data$parent)
s_child = sd(galton.data$child)

(b1 = r*(s_child/s_parent))
```

```
## [1] 0.6462906
```

```r
(b0 = m_child - b1*m_parent)
```

```
## [1] 23.94153
```


How will this change if we regress parent height onto children's?

---


```r
(b1 = r*(s_child/s_parent))
```

```
## [1] 0.6462906
```

```r
(b0 = m_child - b1*m_parent)
```

```
## [1] 23.94153
```



```r
(b1 = r*(s_parent/s_child))
```

```
## [1] 0.3256475
```

```r
(b0 = m_parent - b1*m_child)
```

```
## [1] 46.13535
```

---
## In `R`


```r
fit.1 &lt;- lm(child ~ parent, data = galton.data)
summary(fit.1)
```

```
## 
## Call:
## lm(formula = child ~ parent, data = galton.data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.8050 -1.3661  0.0487  1.6339  5.9264 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 23.94153    2.81088   8.517   &lt;2e-16 ***
## parent       0.64629    0.04114  15.711   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.239 on 926 degrees of freedom
## Multiple R-squared:  0.2105,	Adjusted R-squared:  0.2096 
## F-statistic: 246.8 on 1 and 926 DF,  p-value: &lt; 2.2e-16
```

???

## Things to discuss

- Coefficient estimates
- Statistical tests (covered in more detail soon)

---


![](3-regression_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

## Data, predicted, and residuals


```r
library(broom)
model_info = augment(fit.1)
head(model_info)
```

```
## # A tibble: 6 x 9
##   child parent .fitted .se.fit .resid    .hat .sigma .cooksd .std.resid
##   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
## 1  61.7   70.5    69.5  0.116   -7.81 0.00270   2.22 0.0165       -3.49
## 2  61.7   68.5    68.2  0.0739  -6.51 0.00109   2.23 0.00462      -2.91
## 3  61.7   65.5    66.3  0.137   -4.57 0.00374   2.23 0.00787      -2.05
## 4  61.7   64.5    65.6  0.173   -3.93 0.00597   2.24 0.00931      -1.76
## 5  61.7   64      65.3  0.192   -3.60 0.00735   2.24 0.00966      -1.62
## 6  62.2   67.5    67.6  0.0807  -5.37 0.00130   2.23 0.00374      -2.40
```

---


```r
model_info %&gt;% ggplot(aes(x = parent, y = .fitted)) +
  geom_point() + geom_smooth(se = F, method = "lm") + ggtitle(expression(paste("X is related to ", hat(Y))))+
  scale_x_continuous("X") + scale_y_continuous(expression(hat(Y))) + theme_bw(base_size = 30)
```

![](3-regression_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;
---


```r
model_info %&gt;% ggplot(aes(x = parent, y = .resid)) +
  geom_point() + geom_smooth(se = F, method = "lm") + ggtitle("X is always unrelated to e")+
  scale_x_continuous("X") + scale_y_continuous("e") + theme_bw(base_size = 30)
```

![](3-regression_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

---


```r
model_info %&gt;% ggplot(aes(x = child, y = .fitted)) +
  geom_point() + geom_smooth(se = F, method = "lm") + ggtitle(expression(paste("Y can be related to ", hat(Y))))+
  scale_x_continuous("Y") + scale_y_continuous(expression(hat(Y))) + theme_bw(base_size = 30)
```

![](3-regression_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

---


```r
model_info %&gt;% ggplot(aes(x = child, y = .resid)) +
  geom_point() + geom_smooth(se = F, method = "lm") + ggtitle("Y is sometimes related to e")+
  scale_x_continuous("Y") + scale_y_continuous("e") + theme_bw(base_size = 30)
```

![](3-regression_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;

---


```r
model_info %&gt;% ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() + geom_smooth(se = F, method = "lm") + ggtitle(expression(paste(hat(Y), " is always unrelated to e")))+
  scale_y_continuous("e") + scale_x_continuous(expression(hat(Y))) + theme_bw(base_size = 30)
```

![](3-regression_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---


```r
model_info %&gt;% rename(y = child, x = parent) %&gt;% select(x,y,.fitted,.resid) %&gt;% gather("key", "value") %&gt;%
  ggplot(aes(value, fill = key)) + geom_histogram(bins = 25) + guides(fill = F)+
  facet_wrap(~key, scales = "free") + theme_bw(base_size = 20)
```

![](3-regression_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

---

class: inverse

## Next time... 

Statistical inferences with regression
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
