---
title: "Lab 5: Categorical Predictors/One-way ANOVA"
output: 
  html_document: 
    fig_caption: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: TRUE
    df_print: paged
---

```{r setup, include=FALSE}
# suppress scientific notation
options(scipen = 999)
```


# Purpose

XXX

To quickly navigate to the desired section, click one of the following links:

1. [Regression with categorical predictors](#regression)
1. [Traditional ANOVA](#anova)

```{r message=FALSE}
library(tidyverse) # for plotting and data wrangling
library(rio) # for importing data
library(psych) # for descriptives
```

***

# Regression with categorical predictors{#regression}

## Research scenario

* We'll be looking at a dataset comparing different kinds of treatment for depression. In this study, depressed patients (n = 5 per group) were randomly assigned to one of three groups:

1.	CBT group 
2.	Psychotherapy group 
3.	Control group (received no therapy) 

* After 10 weeks, participants' depression scores were measured. Our dataset will have just 2 variables: `group` (CBT, Psychotherapy or Control) and `depress` (depression scores; lower scores = more depressed).

* **NOTE:**
`1` = CBT; 
`2` = Psychotherapy;
`3` = Control

* Import the data

```{r}
depression <- import("https://raw.githubusercontent.com/uopsych/psy612/master/labs/lab-5/data/depression.csv")
```

### Structure of the data

* The first thing we should check is how the data are structured. We should have a factor called `group` and a numeric variable for depression scores. We'll use the hopefully familiar function`str()` which stands for *structure*.

```{r}
str(depression) # or use tibble::glimpse(), which is a tidyverse function
```

## Recode `group` as a factor

* Okay, it looks like `group` is being read as an integer. We should go ahead and change this now to help make sure we don't make a mistake and use `group` as an integer later on. This is a bit unnecessary - we would find out when we tried to create dummy codes (since the technique we'll use only works with factors), but it is a good habit to get into. 

* We'll use `mutate()` and base R's `factor()`, which can be used to turn variables into factors. At a minimum, you can just put `factor()` around a variable (e.g., `factor(group)`), but we will also provide labels for the factor. To be really clear that we want to work with the "factor" version of this variables, we'll actually create a new variable and call it `group_fct`.

* NOTE: You want to provide labels in the same order as the levels of the factor, so in this case we want them in the order `CBT`, `Psychotherapy`, and `Control` (see above). 

```{r}
depression <- depression %>% 
  mutate(group_fct = factor(group,
                            labels = c("CBT", "Psychotherapy", "Control"))) # order matters here! 
```

* Look at the structure of the data again. Now it's clear that `group_fct` is a factor variable with the correct levels. 

```{r}
str(depression)
```

## Descriptives

* Next, we'll get descriptives for each group using two tidyverse functions. 

* The first is `group_by()` which sets some metadata saying what variable can be used to group observations (we'll use the `group` variable for this). One thing to mention is that `group_by()` itself looks like it doesn't change much which is OK; it basically sets the groups as meta data which other functions (like `summarize()`) can use. 

* The second is `summarize()` which can be used to get summary information about a dataset. When you combine them, it can give you summary information about each group. `summarize()` works sort of like `mutate()`; you put a name on the left-hand side of an `=` and the definition on the right. The main difference is that summarize collapses across rows; either collapsing across the rows within a group or across all rows if there is no grouping variable set (with `group_by()`). We'll use it to get the mean (using base R's `mean()`), standard deviation (using base R's `sd()`), and sample size per group (using tidyverse's `n()`).

* For a refresher on these functions, see [here](https://uopsych.github.io/psy611/labs/lab-5.html#grouping_data){target="_blank"}

```{r}
depression %>% 
  group_by(group_fct) %>%  # telling it to treat group as the group variable
  summarize(mean = mean(depress, na.rm = TRUE),
            sd = sd(depress, na.rm = TRUE),
            n = n()) %>% # don't need to put anything in here; it's looking for n per group
  knitr::kable(digits = 2) # make it look pretty
```

* What's a faster way to do this? 

```{r}
describeBy(depression$depress, depression$group_fct)
```

* NOTE: If you want the output of `psych::describeBy()` as a matrix instead of a list, add `mat = TRUE`. 

```{r}
describeBy(depression$depress, depression$group_fct, mat = TRUE)
```



## Dummy coding

* Categorical predictors with more than two levels are broken up into several smaller variables. In doing so, we take variables that don't have any inherent numerical value to them, e.g. `group` , which takes the values `1`/`CBT`, `2`/`Psychotherapy` or `3`/`Control`, and ascribe meaningful numbers that allow for us to calculate meaningful statistics.

* This actually happens under the hood in R when our independent variable is a factor. Let's see what happens when we put `group_fct` as the IV in our model:

```{r}
model_default <- lm(depress ~ group_fct, data = depression) 
summary(model_default)
```

* Notice that our coefficients are labeled `(Intercept`), `group_fctPsychotherapy` and `group_fctControl`. Why is this the case? Let's remind ourselves of the levels of `group_fct`:

```{r}
levels(depression$group_fct)
```

* R is creating dummy variables for us under the hood. By default, R treats whatever the first level of the factor variable is as the reference group. In this case, CBT was the first level of `group_fct` (because it was initially coded as `1` in our raw data), so the model treated CBT as our reference group.

>**Question:** In the above model output, what does `(Intercept)` mean? 

>**Answer:** the mean of the CBT group

>**Question:** What does the `group_fctPsychotherapy` slope mean? What does the t value mean? 

>**Answer:** The difference between the mean of Psychotherapy and CBT

>**Question:** What does the `group_fctControl` slope mean? What does the t value mean? 

>**Answer:** The difference between the mean of Control and CBT

>**Question:** What does the F value mean? And what does the R^2 mean? 

>**Answer:** It means that the model has a good overall fit to the data. At least one of the group means is different from at least one other group mean. Group explains roughly 76% of the variance in depression scores. 

* However, let's imagine that we have the following (more intuitive) research questions:

1. Is CBT effective (relative to no therapy)? 
2. Is psychotherapy effective (relative to no therapy)?  

>**Question:** What do want our reference group to be to answer these research questions?

>**Answer:** the Control group

* Now let's make the appropriate dummy codes. Recall that we need *k*-1 dummy codes (where *k* is the number of groups). We have 3 groups, so we need 2 dummy codes. 

* Remember, our decision of how to set the dummy codes (which group to set as the **reference group**) should be guided by our research questions. Above, we said we're interested in whether CBT is better than Control and whether psychotherapy is better than Control. This implies that we should make our reference group the Control group, and make a dummy code to represent the difference between CBT and control and a second dummy code for the difference between psychotherapy and the control group.

* There are (as always) a ton of ways to do this in R. Let's go over a few methods: 

### Create new dummy variables with `mutate()`

* You've seen this before from [this slide](https://uopsych.github.io/psy612/lectures/9-m_regression.html#26){target="blank"} in class. 

```{r}
# create new dummy variables containing 1's and 0's
depression <- depression %>%
  mutate(CBT.v.Control = ifelse(group_fct == "CBT", 1, 0), 
         Psychotherapy.v.Control = ifelse(group_fct == "Psychotherapy", 1, 0)) 
```

* View the data frame with these new dummy variables.

```{r}
depression
```

* Run the linear model using these new dummy variables as the IV's.

```{r}
model_dummy1 <- lm(depress ~ CBT.v.Control + Psychotherapy.v.Control, data = depression) 
summary(model_dummy1)
```

>**Question:** What does the intercept mean? 

>**Answer:** The mean of the Control group.

>**Question:** What does the `CBT.v.Control` slope mean?  This should be pretty obvious...

>**Answer:** The difference in means between the CBT group and Control group. 

>**Question:** What does the `Psychotherapy.v.Control` slope mean? Again, obvious.

>**Answer:** The difference in means between the Pyschotherapy group and Control group. 

>**Question:** How does the F value and R^2 we got from this model compare to our last model with different (underlying) dummy codes? 

>**Answer:** They are the exact same! 

### Contrast Matrix

* Now we're going use another method to create our dummy codes by creating a contrast matrix, which is basically just a set of dummy codes (or effects codes, as we'll discuss in a moment). When we pass a factor to `lm()` it uses a contrast matrix under the hood (which is what happened with the first model we ran. Although R creates the contrast matrix automatically with certain default assumptions, you can set it yourself if you have a specific set of codes in mind (which we do).

* Use `contrasts()` to view the default contrast matrix associated with our grouping variable. This function expects the factor variable that we are trying to view the contrasts for (in this case, `group_fct`) as the first argument. 

```{r}
contrasts(depression$group_fct)  
```

* Again, by default our contrasts are not how we want them because we want `Control` to be the reference group. To manually specify our dummy codes, we'll use the function `contr.treatment()`, which will return a contrast matrix with specific characteristics, depending on what we tell it. The first argument, `n` is the number of levels of the factor variable (in this case, `n = 3`). The second arugment, `base` refers to the level of the factor taht should be considered the reference group -- in this case, since `Control` is the third level of `group_fct`, we will put `base = 3`.

```{r}
contr.treatment(n = 3, base = 3)    
```

* Now we will overwrite the default contrast matrix for `group_fct` with the one we just manually specified.

```{r}
contrasts(depression$group_fct) <- contr.treatment(n = 3, base = 3)    
```

* Now look at the structure of the data again. What do you notice about `group_fct`?

```{r}
str(depression)
```

* Let's take a closer look at `group_fct` using `attributes()`...

```{r}
attributes(depression$group_fct)
```

* Run the linear model with `group_fct` (now containing our desired dummy codes) as the IV 

```{r}
model_dummy2 <- lm(depress ~ group_fct, data = depression) 
summary(model_dummy2)
```

>**Question:** How does this compare to the output from the model that contained individual dummy variables (i.e. `CBT.v.Control` and `Psychotherapy.v.Control`) as the IV's? 

>**Answer:** It is exactly the same!

### Re-order levels of your factor

* Let's take another look at the levels of `group_fct`

```{r}
levels(depression$group_fct)
```

* We can manually change the order of the levels by using `factor()` and manually specifying the `levels` argument to contain the order we want. Again, since R treats the first level of the factor as the reference group, and we want `Control` to be the reference group in order to obtain our contrasts of interests when we run the linear model, we will create a new version of `group_fct` called `group_fct_relevel` and make `Control` the first level of the factor in this new variable.

```{r}
depression <- depression %>% 
  mutate(group_fct_relevel = factor(group_fct, levels = c("Control",         # now level 1
                                                  "CBT",             # now level 2
                                                  "Psychotherapy"))) # now level 3
```

* To double check that this worked, let's look at the levels of `group_fct_relevel`

```{r}
levels(depression$group_fct_relevel)
```

* Now when we run the linear model, the contrast matrix that will be automatically generated will correspond to the correct contrasts we want. To verify this, let's re-run the linear model (yet again!) with the re-leveled `group_fct_relevel` variable as the IV. 

```{r}
model_dummy3 <- lm(depress ~ group_fct_relevel, data = depression) 
summary(model_dummy3)
```

* VoilÃ , it's the exact same as our last two models! 

## Effects coding

* Instead of dummy coding, we can instead use **effects coding** (also called "deviation coding") to compare individual group means to the overall mean of the dependent variable (i.e. the grand mean). In R, we do this in basically the same way as dummy coding, but just change the values we use to set the codes. 

* **NOTE: This will change how we interpret our coefficients!**. When using effects coding, the intercept represents the grand mean. The coefficients of each of the effect-coded variables is equal to the difference between the mean of the group coded 1 and the grand mean. 

* With effects coding, the reference group will end up being coded with all `-1`'s.
 
* Let's imagine our research questions are as follows: 

-Is CBT effective compared to the overall sample? 
-Is Psychotherapy effective compared to the overall sample?

* We'll create our contrast matrix of effects codes in a very similar way to how we made our dummy codes. The only difference is that this time we will use `contr.sum()`, again telling it the number of levels of our grouping factor (`n = 3`)

```{r}
contr.sum(n = 3)
```

* And as before with dummy codes, we overwrite the default contrast matrix with our effect codes.

```{r}
contrasts(depression$group_fct) <- contr.sum(n = 3)
```

* Run the linear model with effects coding

```{r}
model_ec <- lm(depress ~ group_fct, data = depression) 
summary(model_ec)
```

>**Question:** How does the overall model fit compare to that from the model(s) that used dummy coding? 

>**Answer:** It is exactly the same!

* There are many other contrast coding schemes besides dummy and effects coding. You can read more about that [here](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/){target="_blank"}. 

## Factor vs. numeric/character

* This whole time we've been working with our grouping variable as a factor `group_fct`. For a moment, let's consider what would have happened if we forgot to make it a factor. Remember that in our `depression` data frame, `group` is an integer.

```{r}
model_numeric <- lm(depress ~ group, data = depression) 
summary(model_numeric)
```

* Compare this with the output from our model using `group_fct`:

```{r echo=FALSE}
summary(lm(depress ~ group_fct_relevel, data = depression))
```

>**Question:** What do you notice about the degrees of freedom in each of these models? 

>**Answer:** When group is numeric, df_denominator = 1 (which is wrong); when group is a factor, df_denominator = number of groups - 1

***

# Traditional ANOVA{#anova}

* We have just reviewed in detail how to do an ANOVA within a linear regression framework. We will briefly review how to generate a traditional ANOVA table, though this will give us the same information we already got from our regression model, so we are not going to go over the old-school ANOVA method in great detail. 

* To get an ANOVA table, you can use`stats::aov()` and provide it with the same information you would pass to `lm()`, namely a formula (e.g. `IV ~ DV`) and the `data`. Again, make sure that the categorical IV is a factor. 

```{r}
model_anova <- aov(depress ~ group_fct, data = depression)
summary(model_anova)
```

* To calculate pairwise comparisons between group levels, use `pairwise.t.test()`. This function takes arguments `x` (the outcome variable), `g` (the grouping variable) an `p.adjust.method` (e.g. "bonferroni" or "holm").

```{r}
pairwise.t.test(x = depression$depress, g = depression$group_fct, p.adjust.method = "none")
```

* Bonferroni correction

```{r}
pairwise.t.test(x = depression$depress, g = depression$group_fct, p.adjust.method = "bonferroni")
```

* Holm correction

```{r}
pairwise.t.test(x = depression$depress, g = depression$group_fct, p.adjust.method = "holm")
```

>**Question:** What difference do you notice about the Bonferroni vs. Holm correction? 

>**Answer:** Bonferroni is more conservative

***

# Minihacks


## Minihack 1

***

## Minihack 2

***

## Minihack 3